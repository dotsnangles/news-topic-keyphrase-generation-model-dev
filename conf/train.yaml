path:
  PROJECT_NAME: "news-topic-keyphrase-generation-model-dev"
  RUN_ID: "v4_run_1"
  TRAIN_DATA_PATH: "data/model_dev/model_dev_v4_train.hf"
  EVAL_DATA_PATH: "data/model_dev/model_dev_v4_eval.hf"
  MODEL_CHECKPOINT: "paust/pko-t5-base"
  NOTEBOOK_NAME: "./train_seq2seq_plm.ipynb"

global_args:
  batch_size: 8
  epochs: 50
  learning_rate: 3e-6
  early_stopping_patience: 3
training_args:
  report_to: wandb
  num_train_epochs: ${epochs}
  per_device_train_batch_size: ${batch_size}
  per_device_eval_batch_size: ${batch_size}
  gradient_accumulation_steps: 1
  optim: adamw_torch  # 'adamw_torch' or 'adamw_hf'
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  weight_decay: 0.01
  lr_scheduler_type: linear  # 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', 'constant', 'constant_with_warmup'
  warmup_ratio: 0
  save_total_limit: 2
  load_best_model_at_end: True
  metric_for_best_model: eval_loss
  save_strategy: epoch
  evaluation_strategy: epoch
  logging_strategy: steps
  logging_first_step: True
  predict_with_generate: False
  generation_max_length: 64
  # generation_num_beams: generation_num_beams
  fp16: False