{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig, AutoTokenizer, \n",
    "    T5TokenizerFast, T5ForConditionalGeneration, \n",
    "    AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, \n",
    "    AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "from datasets import load_metric, Dataset\n",
    "\n",
    "import wandb\n",
    "import nltk\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NGPU = torch.cuda.device_count()\n",
    "NCPU = os.cpu_count()\n",
    "NGPU, NCPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### paths and names\n",
    "\n",
    "DATA_PATH = 'data/model_dev/model_dev_v3.pickle'\n",
    "MODEL_CHECKPOINT = '.log/paust_pko_t5_base_v3_run_5/checkpoint-11310'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "metric = load_metric('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"generate keyphrases: \"\n",
    "\n",
    "max_input_length = 1024\n",
    "max_target_length = 64\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"input_text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    labels = tokenizer(examples[\"target_text\"], max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data_df).shuffle(seed=100).train_test_split(0.2, seed=100)\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0400cdf61d549ab87c8ba6da6789b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/9346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401c4166a6684d1db9efe3f0d1e15756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/2337 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 9346\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2337\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(preprocess_function, \n",
    "                                  batched=True, \n",
    "                                  num_proc=NCPU, \n",
    "                                  remove_columns=train_dataset.column_names)\n",
    "\n",
    "eval_dataset = eval_dataset.map(preprocess_function, \n",
    "                                batched=True, \n",
    "                                num_proc=NCPU, \n",
    "                                remove_columns=eval_dataset.column_names)\n",
    "print(train_dataset)\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = eval_dataset[:10]\n",
    "input_ids = torch.tensor(inputs['input_ids'])\n",
    "attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "labels = tokenizer.batch_decode(inputs['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_decoded = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "# print(f'inputs_decoded: {inputs_decoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=64)\n",
    "predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_at_k_for_sample(label, prediction, k):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # convert label and prediction strings to sets of key-phrases\n",
    "    label_lst = [key_phrase.strip() for key_phrase in label.split(';') if key_phrase != '']\n",
    "    label_lst = [key_phrase for key_phrase in label_lst if key_phrase != '']\n",
    "    label_set = set(label_lst)\n",
    "    # print(f'label_set: {label_set}')\n",
    "    \n",
    "    # split the predicted key-phrases and their scores\n",
    "    prediction_lst = [key_phrase.strip() for key_phrase in prediction.split(';') if key_phrase != '']\n",
    "    prediction_lst = [key_phrase for key_phrase in prediction_lst if key_phrase != ''][:k]\n",
    "    prediction_set = set(prediction_lst)\n",
    "    # prediction_set = set(p[0] for p in predictions[:k])\n",
    "    # print(f'prediction_set: {prediction_set}')\n",
    "    \n",
    "    # calculate true positives, false positives, and false negatives\n",
    "    for keyphrase in prediction_set:\n",
    "        if keyphrase in label_set:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "    \n",
    "    for keyphrase in label_set:\n",
    "        if keyphrase not in prediction_set:\n",
    "            false_negatives += 1\n",
    "    \n",
    "    # print(f'true_positives: {true_positives}')    \n",
    "    # print(f'false_positives: {false_positives}')\n",
    "    # print(f'false_negatives: {false_negatives}')\n",
    "\n",
    "    # calculate precision, recall, and F1 score\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    if precision == 0 or recall == 0:\n",
    "        return 0\n",
    "    \n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['토트넘; 우승; 아스널; 맨시티; 승점 차; 빅4; 브라이튼; 강등 전쟁; 슈퍼컴퓨터; 노팅엄 포레스트',\n",
       "  '경부고속도; 지하화; 서울 리니어파크; 강남 도심; 상부 공간; 녹지 공간; 연결; 서울시장; 지하도로; 착공',\n",
       "  '중기부; 중소기업부; 수출활성화; TF(태스크포스); 글로벌 강소기업; 육성; 1000+ 프로젝트; 글로벌 비즈니스센터(GBC); 개편전략; 수출인큐베이터(BI)',\n",
       "  '하태경; 윤석열 대통령; 부산세계박람회; BIE; 일광수산 횟집; 친일몰이; 더탐사; 선라이즈; 조선시대 지명; 괴담 언론',\n",
       "  'SSG 추신수; 외야 수비; 1번 우익수; 대전 한화전; 첫 수비 출장; 지명타자; 개막 7경기; 왼쪽 팔꿈치 수술; 스프링캠프; 선발 라인업',\n",
       "  '전처 남친 살해; 재판; 혐의; 징역 19년; B씨; 이혼; 주거지; 1심; C씨; 대법원',\n",
       "  '은행권 발행; 코코본드; 조건부자본증권; 발행 잔액; 상각; 회계상 자본; 상각 사유; 자기자본비율; 투자심리 위축; 금융시장',\n",
       "  '수지; 그림 그리기; 취미 생활; 작업실; 인형 같은 비주얼; 상큼한 매력; 자유로움; 꾸준히 하기; 이두나!; 팬들',\n",
       "  '승아 양; 어머니; 인형; 발인식; 음주 운전자; 치사; 유가족; 오빠; 친구들; 처벌 강화',\n",
       "  '이태곤 감독; 보라! 데모라; 이보라; 연애서; 유인나; 이수혁; 한상진; 현실 공감 로맨스; 성장; 보라! 데보라'],\n",
       " ['토트넘; 빅4; 슈퍼컴퓨터; 우승; 브라이턴; 뉴캐슬; 맨체스터; 승점; 강등 전쟁; 레스터시티',\n",
       "  '경부고속도로; 양재~한남; 지하화; 상부공간; 이용방안; 서울 리니어파크; 강남도심; 동서 지역; 리오 공원; 복합문화 공간',\n",
       "  '중소벤처기업부; 수출 활성화; 민관 협·단체장; 연구기관; 합동 대응체계; 수출바우처; 글로벌 비즈니스센터; 수출바우처; 수출바우처 지원; 수출 선도기업; 스마트공장 우대지원',\n",
       "  '하태경; 윤석열 대통령; 부산세계박람회; 부산 횟집; 친일몰이; 더탐사; 일광; 욱일기 상징; 일제강점기; 조선시대 지명',\n",
       "  'SSG 추신수; 외야 수비; 추신수; 선발 라인업; 1번타자 우익수; 개막 7경기; 첫 수비; 주전 우익수; 베이스러닝; 선발 라인업; 선발투수',\n",
       "  '이혼한 전 부인; 남자친구; 살해; 징역 19년; 전처 남친; 대법원; 살인 혐의; C씨; 흉기로 살해; 원심 확정; 양형',\n",
       "  '국내 은행권; 코코본드; 상각 사태; 금융당국; CS; AT1; 금융지주; 보험업권; 자기자본비율; 손실 부담',\n",
       "  '수지; 취미; 그림; 자유로움; 유튜브; 작업실; 작업실; 국민 첫사랑; 국민 첫사랑; 넷플릭스 드라마; 이두나!',\n",
       "  '승아; 인형; 어머니; 운전자; 차량; 사망; 추모; 영정사진; 치료; 처벌',\n",
       "  '이태곤 감독; 드라마; 보라! 데보라; 연출; 아경 작가; 캐릭터들; 현실적인 대사; 공감; 인물들의 솔직함; 성장'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_at_k_for_batch(labels, predictions, k):\n",
    "    f1_scores =[]\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        f1_scores.append(f1_score_at_k_for_sample(label, prediction, k))\n",
    "\n",
    "    print(f1_scores)\n",
    "    return sum(f1_scores) / len(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.20000000000000004, 0, 0.6, 0.4210526315789474, 0.3, 0.20000000000000004, 0.33333333333333326, 0.20000000000000004, 0.3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30543859649122806"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_at_k_for_batch(labels, prediction, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score_at_k_for_sample(labels[9], prediction[9], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_for_sample(label, prediction, k):\n",
    "\n",
    "    # convert label and prediction strings to sets of key-phrases\n",
    "    label_lst = [key_phrase.strip() for key_phrase in label.split(';') if key_phrase != '']\n",
    "    label_lst = [key_phrase for key_phrase in label_lst if key_phrase != '']\n",
    "    # print(label_lst)\n",
    "    \n",
    "    # split the predicted key-phrases and their scores\n",
    "    prediction_lst = [key_phrase.strip() for key_phrase in prediction.split(';') if key_phrase != '']\n",
    "    prediction_lst = [key_phrase for key_phrase in prediction_lst if key_phrase != ''][:k]\n",
    "    # print(prediction_lst)\n",
    "\n",
    "    \"\"\"Define Jaccard Similarity function for two sets\"\"\"\n",
    "    intersection = len(list(set(label_lst).intersection(prediction_lst)))\n",
    "    union = (len(label_lst) + len(prediction_lst)) - intersection\n",
    "\n",
    "    # print(union)\n",
    "    # print(intersection)\n",
    "\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_for_batch(labels, predictions, k):\n",
    "    jaccard_similarities =[]\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        jaccard_similarities.append(jaccard_similarity_for_sample(label, prediction, k))\n",
    "\n",
    "    print(jaccard_similarities)\n",
    "    return sum(jaccard_similarities) / len(jaccard_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3333333333333333, 0.1111111111111111, 0.0, 0.42857142857142855, 0.25, 0.17647058823529413, 0.1111111111111111, 0.17647058823529413, 0.1111111111111111, 0.17647058823529413]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1874649859943978"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity_for_batch(labels, predictions, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
